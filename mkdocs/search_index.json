{
    "docs": [
        {
            "location": "/", 
            "text": "Identifying harmful mutations in microbial populations with Tn-seq\n\n\nThis repository contains lesson materials, instructions, and scripts for analyzing Tn-seq data as presented during the \nBodega Bay 2016 bioinformatics course\n.\n\n\nDISCLAIMER:\n This lesson is written for the particular flavor of Tn-seq data generation and analysis that I am familiar with in my lab as described \nhere\n, but modifications to the general Tn-seq scheme exist. Also, keep in mind that, as was determined at #ngs2015\n\n\n\n\nSet up Amazon instance and install dependencies\n\n\nBefore we get going with data analysis, we need to set up our environment and install some dependencies. On Amazon Web Services, launch Ubuntu 14.04 LTS (64-bit) on an m3.2xlarge instance. \nBefore you click 'Review and Launch',\n, increase the root file system size to 12 GB. You will need to create a new private key if you do not already have one.\n\n\nWhen the instance becomes available, copy its address, open a Terminal and connect to it via ssh:\n\n\nssh -i keyfile.pem ubuntu@copy.address.here.amazonaws.com\n\n\n\nNow let's install software:\n\n\nsudo apt-get update\nsudo apt-get -y upgrade\nsudo apt-get -y install autoconf automake bison build-essential default-jdk default-jre expat fastqc fastx-toolkit  g++ gcc git libboost-all-dev libbz2-dev libncurses5-dev libpcre++-dev libpcre3-dev make parallel python-dev python-setuptools  unzip wget zlib1g-dev\n\n\n\nWhile I introduce my research and give an overview of Tn-seq, download and unzip the data file we'll be using:\n\n\nmkdir ~/data\nsudo mkfs.ext4 -E nodiscard /dev/xvdc\nsudo mount /dev/xvdc ~/data\nsudo chown ubuntu ~/data\ncd ~/data\nwget http://dib-training.ucdavis.edu.s3.amazonaws.com/2016-bodega/tnseq_reads.fastq.gz\ngunzip tnseq_reads.fastq.gz \n md5sum tnseq_reads.fastq.gz\n\n\n\nThis lesson is a bit of a disk hog, so let's mount the other SSD included with the m3.2xlarge instance to an \nanalysis\n directory:\n\n\nsudo umount /dev/xvdb\nmkdir ~/analysis\nsudo mount /dev/xvdb ~/analysis\nsudo chown ubuntu ~/analysis\n\n\n\nWe will also be using some other software packages that require manual installation. First, we'll install Heng Li's \nbioawk\n, an extension of the powerful GNU \nawk\n language which readily parses and manipulates common bioinformatics file formats like fastx and sam:\n\n\nsudo mkdir /sw \nsudo chown ubuntu /sw\nchmod 775 /sw\ncd /sw\ngit clone https://github.com/lh3/bioawk.git\ncd bioawk\nmake\n\n\n\nNext, install \npullseq\n. I've found it to be a really handy tool for grabbing reads from fastx files by name or by matching a regular expression:\n\n\ncd /sw\ngit clone https://github.com/bcthomas/pullseq.git\ncd pullseq\n./bootstrap\n./configure\nmake\nsudo make install\n\n\n\nInstall Trimmomatic:\n\n\ncd /sw \n wget http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.35.zip\nunzip Trimmomatic-0.35.zip\necho 'trimmomatic=/sw/Trimmomatic-0.35/trimmomatic-0.35.jar' \n ~/.bashrc\n\n\n\nNow let's install \nsamtools\n \nversion 1.2\n:\n\n\ncd /sw\nwget https://github.com/samtools/samtools/releases/download/1.2/samtools-1.2.tar.bz2\ntar -xvjf samtools-1.2.tar.bz2\ncd samtools-1.2\nmake\n\n\n\nInstall \nbowtie\n version 1.1.2:\n\n\ncd /sw\nwget http://sourceforge.net/projects/bowtie-bio/files/bowtie/1.1.2/bowtie-1.1.2-src.zip\nunzip bowtie-1.1.2-src.zip \n cd bowtie-1.1.2\nmake\n\n\n\nMake sure \nbash\n knows where we've installed our packages:\n\n\necho 'PATH=~/tnseq/scripts:$PATH' \n ~/.bashrc\necho 'PATH=/sw/bioawk:$PATH' \n ~/.bashrc\necho 'PATH=/sw/samtools-1.2:$PATH' \n ~/.bashrc\necho 'PATH=/sw/bowtie-1.1.2:$PATH' \n ~/.bashrc\nsource ~/.bashrc\nwhich bioawk\n\n\n\nWe also need to install \nBioPython\n:\n\n\nsudo easy_install pip setuptools\nsudo -H pip install --upgrade pip setuptools\nsudo -H pip install pyopenssl ndg-httpsclient pyasn1\nsudo -H pip install biopython\n\n\n\nFinally, clone the lesson repo into your home directory:\n\n\ncd ~\ngit clone https://github.com/jbadomics/tnseq.git\n\n\n\nIntroduction to Tn-seq\n\n\nIn this lesson, we'll be analyzing Tn-seq data from an environmental bacterium that we study in the \nBond Lab\n, \nGeobacter sulfurreducens\n. This organism is a model system for microbial metal reduction and extracellular electron transfer, since these microbes obtain metabolic energy by respiring insoluble metal oxides like Fe and Mn located outside the cell. Our lab is interested in identifying the proteins involved in this remarkable ability to transfer electrons across two insulating biological membranes.\n\n\nTn-seq is a hypothesis-generating tool for identifying genes that provide fitness benefit under particular conditions. The procedure requires the following:\n\n\n\n\nA genetically tractable model organism, and\n\n\nits genome sequence.\n\n\n\n\nFirst, cells are randomly mutagenized with a suicide plasmid containing the Mariner transposon (which confers resistance to kanamycin). This transposon is flanked by inverted repeats and integrates into the chromosome at TA sites. A saturated mutant library is created by pooling a number of colonies roughly 10 times the number of genes in the genome. This number depends on two factors:\n\n\n\n\ngenome size\n\n\nGC content (higher GC microbes inherently have fewer TA sites)\n\n\n\n\nThe transposon mutant library we'll be looking at contains ~40,000 individual mutants. Some of them will have no phenotype; others will be lethal (i.e. the transposon insertion has interrupted an essential gene); or, the insertion will cause a fitness defect only under certain conditions.\n\n\nThe entire mutant library is then subjected to two or more different outgrowth conditions, ideally for a known number of cell doublings (more on this later!). Assume a mutation at locus X, which causes a fitness defect under condition 1 but not condition 2. Over a few doubling events under condition 1, cells which carry the locus X mutation will be outcompeted and eventually die off; over the same period under condition 2, cells can continue to grow despite the locus X mutation. After outgrowth, genomic DNA is harvested and submitted for Illumina sequencing to locate the genomic position where the transposon inserted. In condition 1, very few (if any reads) will map, since the mutation caused a fitness defect, whereas in condition 2, more reads will map. Genes with the highest ratios of reads mapped can then be deleted and the phenotype can be verified.\n\n\nGetting down to base-ics\n\n\nLet's look at the molecular steps again. \n\n\nThe original TA site in the genome is duplicated during the transposition event. In addition, a single transposition event will result (theoretically) in two reads that should map to the same insertion site - one on the forward strand, and one on the reverse strand. We will count this as two \nhits\n at one \nsite\n.\n\n\nBut there's a problem: when it comes time to map reads, any read mapping to the reverse strand will need to have it's insertion position corrected. Consider the following example of two mock reads mapped to the first TA site in the genome. Here is the resulting SAM file:\n\n\n@HD VN:1.0  SO:unsorted\n@SQ SN:chr1 LN:3820884\n@PG ID:bowtie2  PN:bowtie2  VN:2.2.6    CL:\nbowtie2-align-s --wrapper basic-0 -x MN1 -S test.sam -q -U simulated.fastq\n\nfwd_read    0   chr1    29  42  20M *   0   0   TATGGAAGAAGTTTGGCTCC    DFEEEEIDDDDDDDDDDDDD\nrev_read    16  chr1    11  42  20M *   0   0   TCCCGAGAAGGTCTGGTTTA    DDDDDDDDDDDDDIEEEEFD\n\n\n\n\nIn column 4, we can see that the reverse read reports an alignment beginning at base 11, when in fact the TA site of insertion is at the end of the read. For this lesson, I define the coordinate of the TA site as the coordinate of the 'A' residue, which in this case is 30. We'll incorporate a step in our workflow to ensure that the forward and reverse reads arising from the same insertion event end up with an identical insertion coordinate reported.\n\n\nTn-seq data analysis workflow\n\n\nRemove phiX reads\n\n\nIn situations where Illumina reads are generated from the same DNA template (e.g. conserved regions of the 16S rRNA gene), it can be hard to differentiate clusters on the Illumina flow cell unless an external control is spiked into the sample, usually phage phiX DNA. Your sequencing provider may \nsay\n they've removed phiX reads, but let's check just to be safe.\n\n\nFirst, create a data analysis directory:\n\n\nmkdir ~/analysis \n cd ~/analysis\n\n\n\nWe'll use bowtie2 to map our Tn-seq reads:\n\n\nbowtie-build ~/tnseq/reference/phiX.fasta phiX\nbowtie -q -S -p $(nproc --all) phiX ~/data/tnseq_reads.fastq phiX.sam\n\n\n\nHave a look at the sam file:\n\n\nless -S phiX.sam\n\n\n\nYou'll notice that we have quite a few reads mapping to phiX. We should remove them from the dataset before we continue. pullseq to the rescue!\n\n\nsamtools view -f 4 phiX.sam | cut -f1 | pullseq -i Tn-seq.fastq -N - \n phiX_removed.fastq\n\n\n\nLet's break this down: \nsamtools view\n with \n-f 4\n collects any \nunmapped\n reads, in sam format. The first column contains the read IDs. These are piped into \npullseq\n using \n-N\n which takes the read names from STDIN (\n-n\n if read IDs are in another file).\n\n\nIn this lesson repository I've also included a shell script called \ncountseq\n which invokes \nbioawk\n to correctly count the number of sequences in any fastq or fasta file, and supports shell wildcard expansion. Make sure that \nphiX_removed.fastq\n contains fewer reads than our raw data:\n\n\ncountseq *.fastq\n\n\n\nRemove transposon sequence, filter, and separate reads by barcode\n\n\nUse \nless\n to have a look at the phiX-removed reads. You should see some patterns: are there multiple barcodes? Do you see any TA insertion sites? Do the 3' ends of the reads look similar?\n\n\nPrevious implementations of this workflow used \nfastx_clipper\n, part of the fastx toolkit, to remove transposon sequence at the 3' end of the read. Unfortunately this was painfully slow.\n\n\nTrimmomatic can do what we want, and is WAY faster. Rather than trim off Illumina adaptors, we can specify a custom file with our transposon sequence to trim:\n\n\njava -Xmx28g -jar $trimmomatic SE -phred33 phiX_removed.fastq tn_removed.fastq ILLUMINACLIP:/home/ubuntu/tnseq/reference/tnseq_adapters.fa:3:30:10 MINLEN:16\n\n\n\nTime to introduce the power of \nbioawk\n. I'm a huge fan of \nbioawk\n. We can use \nawk\n-like language to construct \nif\n statements, match regex patterns, and print reads meeting our criteria in either fasta or fastq format. In addition, \nbioawk\n automatically recognizes and parses these file formats (along with others like GFF and SAM) and assigns logical variables like \n$seq\n to describe the sequence and \n$qual\n to define the quality string.\n\n\nNow we need to discard any reads that did not contain transposon sequence. By this point in our workflow, these reads can be distinguished as still being full-length (51 bp):\n\n\nbioawk -c fastx '{ if(length($seq) != 51) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.fastq \n tn_removed.filtered.fastq\n\n\n\nLet's use bioawk again in a one-liner to capture a length distribution of the filtered reads:\n\n\nbioawk -c fastx '{ print length($seq) }' tn_removed.filtered.fastq | sort | uniq -c\n\n\n\nAs we expect, the overwhelming majority of our data is 20 or 21 bp. Keep in mind that the reads still contain barcode, which we'll remove shortly. But before we get to that, run bioawk to collect the reads of desired length:\n\n\nbioawk -c fastx '{ if(length($seq) \n= 19 \n length($seq) \n 23) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.fastq \n tn_removed.filtered.length.fastq\n\n\n\nRun a quick \ncountseq\n to keep tabs of how many sequences we're discarding at each step:\n\n\ncountseq tn_removed*.fastq\n\n\n\nWhen we go to map reads against the reference genome, it is critical to keep tabs of the genomic position where the insertion occurred. Conceptually it makes sense to reverse complement the reads so that the TA insertion sequence occurs at the 5' end:\n\n\nfastx_reverse_complement -i tn_removed.filtered.length.fastq -o tn_removed.filtered.length.rc.fastq\n\n\n\nWhat if a read doesn't begin with TA? This can happen sometimes, since the transposon does integrate at non-TA sites at ~2% frequency. We can safely remove the non-TA insertion reads with--you guessed it--bioawk:\n\n\nbioawk -c fastx '{ if ($seq !~ /^TA/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.fastq \n \\ tn_removed.filtered.length.rc.TAonly.fastq\n\n\n\nJust to be safe, let's write the reads that \ndon't\n begin with TA to another file:\n\n\nbioawk -c fastx '{ if ($seq !~ /^TA/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.fastq \n nonTA.fastq\n\n\n\nTake another peek at the reads with \nless\n: they should now all begin with TA and the barcode should now appear at the 3' end.\n\n\nTime to separate reads by barcode. This dataset uses 3 barcodes:\n\n\nBC1 CAGT parent \nBC2 GACT low potential electrode outgrowth\nBC3 GTGT high potential electrode outgrowth\n\n\n\n\nNote that some reads end with N. Bioawk and regular expressions to the rescue!\n\n\nbioawk -c fastx '{ if ($seq ~ /GAC[TN]$/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.TAonly.fastq \n BC1.fastq\n\n\n\nChange the regex pattern and run the same command for BC2:\n\n\nbioawk -c fastx '{ if ($seq ~ /CAG[TN]$/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.TAonly.fastq\n BC2.fastq\n\n\n\nMake sure everything adds up:\n\n\ncountseq tn_removed*.fastq\n\n\n\nNow, remove the barcode on each dataset:\n\n\nfastx_trimmer -t 4 -i BC1.fastq -o BC1_barcode_removed.fastq\n\n\n\nMap reads and collect hit statistics\n\n\nThinking ahead: when it comes time to tabulate the insertion coordinates by locus tag, the reference genome name and sequence need to match what we use to map reads to. \nUnfortunately this isn't always the case.\n The safest bet is to pull the genome sequence from the same Genbank file we'll use later for tabulating insertions. Run this little python script:\n\n\ngbk_to_fasta.py Geobacter_sulfurreducens_MN1.gbk\n\n\n\nNow the fun can begin! Use bowtie2 to map reads:\n\n\nbowtie-build Geobacter_sulfurreducens_MN1.fasta MN1\nbowtie -q -p $(nproc --all) -S -n 0 -e 70 -l 28 --nomaqround -y -k 1 -a -m 1 --best MN1 BC1_barcode_removed.fastq BC1.sam\n\n\n\nRepeat the above command for BC2 and BC3.\n\n\nTake a peek at the output sam files:\n\n\nless -S BC1.sam\n\n\n\nand look at a read that mapped to the reverse strand (look for bitwise flag 16). You'll notice that the read ends in TA, which it should if it mapped to the reverse strand, but the coordinate in column 4 refers to the \nfirst\n base aligned reading from left to right. This means we'll need to correct the coordinate for reads mapped to the minus strand so that they have the same coordinate (i.e. TA insertion site) as the forward read that arose from the same insertion event.\n\n\nHow's this for a one-liner:\n\n\nbioawk -c sam '{ if($flag==0) print $qname,$rname,$flag,$pos,$pos+1,length($seq); if($flag==16)  print $qname,$rname,$flag,$pos,$pos+length($seq)-1,length($seq) }' BC1.sam | cut -f2,5 | sort -g -k2 | uniq -c | sed 's/^ *//' | awk -v OFS='\\t' '{ print $2,$3,$1}' \n BC1.hits.txt\n\n\n\nNow have a look at \nBC1.hits.txt\n. It should be a tab-delimited text file with three columns:\n\n\n\n\nthe reference sequence ID (essential for multi-contig genomes)\n\n\nthe position along that reference\n\n\nthe total number of transposon insertions or \"hits\" at that position\n\n\n\n\nCollect hit statistics by gene\n\n\nI am not a Python expert, but in this repo there are two scripts we'll use for converting our \n.hits.txt\n data by locus tag, using a Genbank file of the reference genome containing the annotation and coordinates of each gene feature.\n\n\nmkdir tabulate \n cd tabulate\ntabulate_insertions.py ~/tnseq/reference/Geobacter_sulfurreducens_MN1.gbk ../BC1.hits.txt BC1 0 0.05\n\n\n\nThe last two numbers specify a percentage to trim off the N- and C-terminus, respectively, of the coding sequence. In past analyses we only consider hits within the first 95% of the total gene length\n\n\nAs the script runs, you'll see a scrolling output of genes that do not contain any TA site hits. What is significant about these genes?\n\n\nCalculate log2 ratios to identify genes of interest\n\n\nTwo particular loci should jump out at us: GSU0274 and GSU3259. These genes encode inner membrane cytochromes that function at low and high potential, respectively. So, in the BC2 library (low potential electrode outgrowth), we should see very few hits in GSU0274. Likewise, in the BC3 library, we should see very few hits in GSU3259. Let's use the second script for this:\n\n\ninsertion_statistics_by_locustag.py /tnseq/reference/Geobacter_sulfurreducens_MN1.gbk ../BC2.hits.txt GSU0274 0 0.05\ninsertion_statistics_by_locustag.py /tnseq/reference/Geobacter_sulfurreducens_MN1.gbk ../BC3.hits.txt GSU3259 0 0.05\n\n\n\nto be continued if time permits!", 
            "title": "Home"
        }, 
        {
            "location": "/#identifying-harmful-mutations-in-microbial-populations-with-tn-seq", 
            "text": "This repository contains lesson materials, instructions, and scripts for analyzing Tn-seq data as presented during the  Bodega Bay 2016 bioinformatics course .  DISCLAIMER:  This lesson is written for the particular flavor of Tn-seq data generation and analysis that I am familiar with in my lab as described  here , but modifications to the general Tn-seq scheme exist. Also, keep in mind that, as was determined at #ngs2015", 
            "title": "Identifying harmful mutations in microbial populations with Tn-seq"
        }, 
        {
            "location": "/#set-up-amazon-instance-and-install-dependencies", 
            "text": "Before we get going with data analysis, we need to set up our environment and install some dependencies. On Amazon Web Services, launch Ubuntu 14.04 LTS (64-bit) on an m3.2xlarge instance.  Before you click 'Review and Launch', , increase the root file system size to 12 GB. You will need to create a new private key if you do not already have one.  When the instance becomes available, copy its address, open a Terminal and connect to it via ssh:  ssh -i keyfile.pem ubuntu@copy.address.here.amazonaws.com  Now let's install software:  sudo apt-get update\nsudo apt-get -y upgrade\nsudo apt-get -y install autoconf automake bison build-essential default-jdk default-jre expat fastqc fastx-toolkit  g++ gcc git libboost-all-dev libbz2-dev libncurses5-dev libpcre++-dev libpcre3-dev make parallel python-dev python-setuptools  unzip wget zlib1g-dev  While I introduce my research and give an overview of Tn-seq, download and unzip the data file we'll be using:  mkdir ~/data\nsudo mkfs.ext4 -E nodiscard /dev/xvdc\nsudo mount /dev/xvdc ~/data\nsudo chown ubuntu ~/data\ncd ~/data\nwget http://dib-training.ucdavis.edu.s3.amazonaws.com/2016-bodega/tnseq_reads.fastq.gz\ngunzip tnseq_reads.fastq.gz   md5sum tnseq_reads.fastq.gz  This lesson is a bit of a disk hog, so let's mount the other SSD included with the m3.2xlarge instance to an  analysis  directory:  sudo umount /dev/xvdb\nmkdir ~/analysis\nsudo mount /dev/xvdb ~/analysis\nsudo chown ubuntu ~/analysis  We will also be using some other software packages that require manual installation. First, we'll install Heng Li's  bioawk , an extension of the powerful GNU  awk  language which readily parses and manipulates common bioinformatics file formats like fastx and sam:  sudo mkdir /sw \nsudo chown ubuntu /sw\nchmod 775 /sw\ncd /sw\ngit clone https://github.com/lh3/bioawk.git\ncd bioawk\nmake  Next, install  pullseq . I've found it to be a really handy tool for grabbing reads from fastx files by name or by matching a regular expression:  cd /sw\ngit clone https://github.com/bcthomas/pullseq.git\ncd pullseq\n./bootstrap\n./configure\nmake\nsudo make install  Install Trimmomatic:  cd /sw   wget http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.35.zip\nunzip Trimmomatic-0.35.zip\necho 'trimmomatic=/sw/Trimmomatic-0.35/trimmomatic-0.35.jar'   ~/.bashrc  Now let's install  samtools   version 1.2 :  cd /sw\nwget https://github.com/samtools/samtools/releases/download/1.2/samtools-1.2.tar.bz2\ntar -xvjf samtools-1.2.tar.bz2\ncd samtools-1.2\nmake  Install  bowtie  version 1.1.2:  cd /sw\nwget http://sourceforge.net/projects/bowtie-bio/files/bowtie/1.1.2/bowtie-1.1.2-src.zip\nunzip bowtie-1.1.2-src.zip   cd bowtie-1.1.2\nmake  Make sure  bash  knows where we've installed our packages:  echo 'PATH=~/tnseq/scripts:$PATH'   ~/.bashrc\necho 'PATH=/sw/bioawk:$PATH'   ~/.bashrc\necho 'PATH=/sw/samtools-1.2:$PATH'   ~/.bashrc\necho 'PATH=/sw/bowtie-1.1.2:$PATH'   ~/.bashrc\nsource ~/.bashrc\nwhich bioawk  We also need to install  BioPython :  sudo easy_install pip setuptools\nsudo -H pip install --upgrade pip setuptools\nsudo -H pip install pyopenssl ndg-httpsclient pyasn1\nsudo -H pip install biopython  Finally, clone the lesson repo into your home directory:  cd ~\ngit clone https://github.com/jbadomics/tnseq.git", 
            "title": "Set up Amazon instance and install dependencies"
        }, 
        {
            "location": "/#introduction-to-tn-seq", 
            "text": "In this lesson, we'll be analyzing Tn-seq data from an environmental bacterium that we study in the  Bond Lab ,  Geobacter sulfurreducens . This organism is a model system for microbial metal reduction and extracellular electron transfer, since these microbes obtain metabolic energy by respiring insoluble metal oxides like Fe and Mn located outside the cell. Our lab is interested in identifying the proteins involved in this remarkable ability to transfer electrons across two insulating biological membranes.  Tn-seq is a hypothesis-generating tool for identifying genes that provide fitness benefit under particular conditions. The procedure requires the following:   A genetically tractable model organism, and  its genome sequence.   First, cells are randomly mutagenized with a suicide plasmid containing the Mariner transposon (which confers resistance to kanamycin). This transposon is flanked by inverted repeats and integrates into the chromosome at TA sites. A saturated mutant library is created by pooling a number of colonies roughly 10 times the number of genes in the genome. This number depends on two factors:   genome size  GC content (higher GC microbes inherently have fewer TA sites)   The transposon mutant library we'll be looking at contains ~40,000 individual mutants. Some of them will have no phenotype; others will be lethal (i.e. the transposon insertion has interrupted an essential gene); or, the insertion will cause a fitness defect only under certain conditions.  The entire mutant library is then subjected to two or more different outgrowth conditions, ideally for a known number of cell doublings (more on this later!). Assume a mutation at locus X, which causes a fitness defect under condition 1 but not condition 2. Over a few doubling events under condition 1, cells which carry the locus X mutation will be outcompeted and eventually die off; over the same period under condition 2, cells can continue to grow despite the locus X mutation. After outgrowth, genomic DNA is harvested and submitted for Illumina sequencing to locate the genomic position where the transposon inserted. In condition 1, very few (if any reads) will map, since the mutation caused a fitness defect, whereas in condition 2, more reads will map. Genes with the highest ratios of reads mapped can then be deleted and the phenotype can be verified.", 
            "title": "Introduction to Tn-seq"
        }, 
        {
            "location": "/#getting-down-to-base-ics", 
            "text": "Let's look at the molecular steps again.   The original TA site in the genome is duplicated during the transposition event. In addition, a single transposition event will result (theoretically) in two reads that should map to the same insertion site - one on the forward strand, and one on the reverse strand. We will count this as two  hits  at one  site .  But there's a problem: when it comes time to map reads, any read mapping to the reverse strand will need to have it's insertion position corrected. Consider the following example of two mock reads mapped to the first TA site in the genome. Here is the resulting SAM file:  @HD VN:1.0  SO:unsorted\n@SQ SN:chr1 LN:3820884\n@PG ID:bowtie2  PN:bowtie2  VN:2.2.6    CL: bowtie2-align-s --wrapper basic-0 -x MN1 -S test.sam -q -U simulated.fastq \nfwd_read    0   chr1    29  42  20M *   0   0   TATGGAAGAAGTTTGGCTCC    DFEEEEIDDDDDDDDDDDDD\nrev_read    16  chr1    11  42  20M *   0   0   TCCCGAGAAGGTCTGGTTTA    DDDDDDDDDDDDDIEEEEFD  In column 4, we can see that the reverse read reports an alignment beginning at base 11, when in fact the TA site of insertion is at the end of the read. For this lesson, I define the coordinate of the TA site as the coordinate of the 'A' residue, which in this case is 30. We'll incorporate a step in our workflow to ensure that the forward and reverse reads arising from the same insertion event end up with an identical insertion coordinate reported.", 
            "title": "Getting down to base-ics"
        }, 
        {
            "location": "/#tn-seq-data-analysis-workflow", 
            "text": "", 
            "title": "Tn-seq data analysis workflow"
        }, 
        {
            "location": "/#remove-phix-reads", 
            "text": "In situations where Illumina reads are generated from the same DNA template (e.g. conserved regions of the 16S rRNA gene), it can be hard to differentiate clusters on the Illumina flow cell unless an external control is spiked into the sample, usually phage phiX DNA. Your sequencing provider may  say  they've removed phiX reads, but let's check just to be safe.  First, create a data analysis directory:  mkdir ~/analysis   cd ~/analysis  We'll use bowtie2 to map our Tn-seq reads:  bowtie-build ~/tnseq/reference/phiX.fasta phiX\nbowtie -q -S -p $(nproc --all) phiX ~/data/tnseq_reads.fastq phiX.sam  Have a look at the sam file:  less -S phiX.sam  You'll notice that we have quite a few reads mapping to phiX. We should remove them from the dataset before we continue. pullseq to the rescue!  samtools view -f 4 phiX.sam | cut -f1 | pullseq -i Tn-seq.fastq -N -   phiX_removed.fastq  Let's break this down:  samtools view  with  -f 4  collects any  unmapped  reads, in sam format. The first column contains the read IDs. These are piped into  pullseq  using  -N  which takes the read names from STDIN ( -n  if read IDs are in another file).  In this lesson repository I've also included a shell script called  countseq  which invokes  bioawk  to correctly count the number of sequences in any fastq or fasta file, and supports shell wildcard expansion. Make sure that  phiX_removed.fastq  contains fewer reads than our raw data:  countseq *.fastq", 
            "title": "Remove phiX reads"
        }, 
        {
            "location": "/#remove-transposon-sequence-filter-and-separate-reads-by-barcode", 
            "text": "Use  less  to have a look at the phiX-removed reads. You should see some patterns: are there multiple barcodes? Do you see any TA insertion sites? Do the 3' ends of the reads look similar?  Previous implementations of this workflow used  fastx_clipper , part of the fastx toolkit, to remove transposon sequence at the 3' end of the read. Unfortunately this was painfully slow.  Trimmomatic can do what we want, and is WAY faster. Rather than trim off Illumina adaptors, we can specify a custom file with our transposon sequence to trim:  java -Xmx28g -jar $trimmomatic SE -phred33 phiX_removed.fastq tn_removed.fastq ILLUMINACLIP:/home/ubuntu/tnseq/reference/tnseq_adapters.fa:3:30:10 MINLEN:16  Time to introduce the power of  bioawk . I'm a huge fan of  bioawk . We can use  awk -like language to construct  if  statements, match regex patterns, and print reads meeting our criteria in either fasta or fastq format. In addition,  bioawk  automatically recognizes and parses these file formats (along with others like GFF and SAM) and assigns logical variables like  $seq  to describe the sequence and  $qual  to define the quality string.  Now we need to discard any reads that did not contain transposon sequence. By this point in our workflow, these reads can be distinguished as still being full-length (51 bp):  bioawk -c fastx '{ if(length($seq) != 51) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.fastq   tn_removed.filtered.fastq  Let's use bioawk again in a one-liner to capture a length distribution of the filtered reads:  bioawk -c fastx '{ print length($seq) }' tn_removed.filtered.fastq | sort | uniq -c  As we expect, the overwhelming majority of our data is 20 or 21 bp. Keep in mind that the reads still contain barcode, which we'll remove shortly. But before we get to that, run bioawk to collect the reads of desired length:  bioawk -c fastx '{ if(length($seq)  = 19   length($seq)   23) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.fastq   tn_removed.filtered.length.fastq  Run a quick  countseq  to keep tabs of how many sequences we're discarding at each step:  countseq tn_removed*.fastq  When we go to map reads against the reference genome, it is critical to keep tabs of the genomic position where the insertion occurred. Conceptually it makes sense to reverse complement the reads so that the TA insertion sequence occurs at the 5' end:  fastx_reverse_complement -i tn_removed.filtered.length.fastq -o tn_removed.filtered.length.rc.fastq  What if a read doesn't begin with TA? This can happen sometimes, since the transposon does integrate at non-TA sites at ~2% frequency. We can safely remove the non-TA insertion reads with--you guessed it--bioawk:  bioawk -c fastx '{ if ($seq !~ /^TA/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.fastq   \\ tn_removed.filtered.length.rc.TAonly.fastq  Just to be safe, let's write the reads that  don't  begin with TA to another file:  bioawk -c fastx '{ if ($seq !~ /^TA/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.fastq   nonTA.fastq  Take another peek at the reads with  less : they should now all begin with TA and the barcode should now appear at the 3' end.  Time to separate reads by barcode. This dataset uses 3 barcodes:  BC1 CAGT parent \nBC2 GACT low potential electrode outgrowth\nBC3 GTGT high potential electrode outgrowth  Note that some reads end with N. Bioawk and regular expressions to the rescue!  bioawk -c fastx '{ if ($seq ~ /GAC[TN]$/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.TAonly.fastq   BC1.fastq  Change the regex pattern and run the same command for BC2:  bioawk -c fastx '{ if ($seq ~ /CAG[TN]$/) { print \"@\"$name; print $seq; print \"+\"; print $qual; }}' tn_removed.filtered.length.rc.TAonly.fastq  BC2.fastq  Make sure everything adds up:  countseq tn_removed*.fastq  Now, remove the barcode on each dataset:  fastx_trimmer -t 4 -i BC1.fastq -o BC1_barcode_removed.fastq", 
            "title": "Remove transposon sequence, filter, and separate reads by barcode"
        }, 
        {
            "location": "/#map-reads-and-collect-hit-statistics", 
            "text": "Thinking ahead: when it comes time to tabulate the insertion coordinates by locus tag, the reference genome name and sequence need to match what we use to map reads to.  Unfortunately this isn't always the case.  The safest bet is to pull the genome sequence from the same Genbank file we'll use later for tabulating insertions. Run this little python script:  gbk_to_fasta.py Geobacter_sulfurreducens_MN1.gbk  Now the fun can begin! Use bowtie2 to map reads:  bowtie-build Geobacter_sulfurreducens_MN1.fasta MN1\nbowtie -q -p $(nproc --all) -S -n 0 -e 70 -l 28 --nomaqround -y -k 1 -a -m 1 --best MN1 BC1_barcode_removed.fastq BC1.sam  Repeat the above command for BC2 and BC3.  Take a peek at the output sam files:  less -S BC1.sam  and look at a read that mapped to the reverse strand (look for bitwise flag 16). You'll notice that the read ends in TA, which it should if it mapped to the reverse strand, but the coordinate in column 4 refers to the  first  base aligned reading from left to right. This means we'll need to correct the coordinate for reads mapped to the minus strand so that they have the same coordinate (i.e. TA insertion site) as the forward read that arose from the same insertion event.  How's this for a one-liner:  bioawk -c sam '{ if($flag==0) print $qname,$rname,$flag,$pos,$pos+1,length($seq); if($flag==16)  print $qname,$rname,$flag,$pos,$pos+length($seq)-1,length($seq) }' BC1.sam | cut -f2,5 | sort -g -k2 | uniq -c | sed 's/^ *//' | awk -v OFS='\\t' '{ print $2,$3,$1}'   BC1.hits.txt  Now have a look at  BC1.hits.txt . It should be a tab-delimited text file with three columns:   the reference sequence ID (essential for multi-contig genomes)  the position along that reference  the total number of transposon insertions or \"hits\" at that position", 
            "title": "Map reads and collect hit statistics"
        }, 
        {
            "location": "/#collect-hit-statistics-by-gene", 
            "text": "I am not a Python expert, but in this repo there are two scripts we'll use for converting our  .hits.txt  data by locus tag, using a Genbank file of the reference genome containing the annotation and coordinates of each gene feature.  mkdir tabulate   cd tabulate\ntabulate_insertions.py ~/tnseq/reference/Geobacter_sulfurreducens_MN1.gbk ../BC1.hits.txt BC1 0 0.05  The last two numbers specify a percentage to trim off the N- and C-terminus, respectively, of the coding sequence. In past analyses we only consider hits within the first 95% of the total gene length  As the script runs, you'll see a scrolling output of genes that do not contain any TA site hits. What is significant about these genes?", 
            "title": "Collect hit statistics by gene"
        }, 
        {
            "location": "/#calculate-log2-ratios-to-identify-genes-of-interest", 
            "text": "Two particular loci should jump out at us: GSU0274 and GSU3259. These genes encode inner membrane cytochromes that function at low and high potential, respectively. So, in the BC2 library (low potential electrode outgrowth), we should see very few hits in GSU0274. Likewise, in the BC3 library, we should see very few hits in GSU3259. Let's use the second script for this:  insertion_statistics_by_locustag.py /tnseq/reference/Geobacter_sulfurreducens_MN1.gbk ../BC2.hits.txt GSU0274 0 0.05\ninsertion_statistics_by_locustag.py /tnseq/reference/Geobacter_sulfurreducens_MN1.gbk ../BC3.hits.txt GSU3259 0 0.05  to be continued if time permits!", 
            "title": "Calculate log2 ratios to identify genes of interest"
        }
    ]
}